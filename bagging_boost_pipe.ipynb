{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7P-dvZUtRki"
      },
      "source": [
        "First\n",
        "\n",
        "Evaluate the performance of the following individual regression models using 5-fold cross validation using only the training data:\n",
        "\n",
        "\n",
        "Data split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QF-nRSlNAKbc"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# select 2000 of the dataset\n",
        "file = pd.read_csv('/content/sample_data/california_housing_test.csv')\n",
        "file.head(2000)\n",
        "X, y = fetch_california_housing(return_X_y=True)\n",
        "X = X[:2000,:]\n",
        "y = y[:2000]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0nbntVHN_R9"
      },
      "source": [
        "1) CLF1: Linear regression model, i.e., LinearRegression()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0UUTeuktNgn",
        "outputId": "697aec77-830a-4c16-9293-607caa12d347"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE: 0.30 (+/- 0.03) [CLF1]\n"
          ]
        }
      ],
      "source": [
        "pipe_linR = Pipeline([['scaler', StandardScaler()],['linR', LinearRegression()]])\n",
        "pipe_linR.fit(X_train,y_train)\n",
        "label = 'CLF1'\n",
        "scores_linR_1=cross_val_score(estimator=pipe_linR,X=X_train,y=y_train,cv=5,scoring='neg_mean_squared_error')\n",
        "print(\"MSE: %0.2f (+/- %0.2f) [%s]\"% (-scores_linR_1.mean(), scores_linR_1.std(), label))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmGtakmFtLaO"
      },
      "source": [
        "2）Decision tree regressor, i.e, DecisionTreeRegressor(max_depth=1, criterion=’squared_error’)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQ55WjCJ1GnH",
        "outputId": "1a37d13d-4eda-42d5-8d05-ebe457eecccf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE: 0.53 (+/- 0.04) [Decision tree regressor]\n"
          ]
        }
      ],
      "source": [
        "pipe_deciTreeReg = Pipeline([['scaler', StandardScaler()],['deciTreeReg', DecisionTreeRegressor(max_depth=1, criterion='squared_error')]])\n",
        "pipe_deciTreeReg.fit(X_train,y_train)\n",
        "labe2 = 'Decision tree regressor'\n",
        "scores_deciTreeReg_1=cross_val_score(estimator=pipe_deciTreeReg,X=X_train,y=y_train,cv=5,scoring='neg_mean_squared_error')\n",
        "print(\"MSE: %0.2f (+/- %0.2f) [%s]\"% (-scores_deciTreeReg_1.mean(), scores_deciTreeReg_1.std(), labe2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3aTrFSHN7vA"
      },
      "source": [
        "3）Support vector regression model with a linear kernel, i.e, SVR(kernel=’linear’)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUeF267zpAyd",
        "outputId": "74c88860-c4bb-4f1c-c2db-a74101b0237f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE: 0.33 (+/- 0.06) [Support vector regression]\n"
          ]
        }
      ],
      "source": [
        "pipe_supVecReg = Pipeline([['scaler', StandardScaler()],['supVecReg', SVR(kernel='linear')]])\n",
        "pipe_supVecReg.fit(X_train,y_train)\n",
        "labe3 = 'Support vector regression'\n",
        "scores_supVecReg_1=cross_val_score(estimator=pipe_supVecReg,X=X_train,y=y_train,cv=5,scoring='neg_mean_squared_error')\n",
        "print(\"MSE: %0.2f (+/- %0.2f) [%s]\"% (-scores_supVecReg_1.mean(), scores_supVecReg_1.std(), labe3)) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2aKBO5uNxPl"
      },
      "source": [
        "Second\n",
        "\n",
        "Build a bagging regression model for each classifier and evaluate the \n",
        "performance of the bagging model using 5-fold cross validation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8_a-2us3kGI"
      },
      "source": [
        "1) linear regression with bagging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBHjk-YHtr7a",
        "outputId": "21211824-0bd9-4b02-8ad5-b9fc23f8738d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
          ]
        }
      ],
      "source": [
        "params_linR = {'n_estimators': np.arange(50, 250, 20), 'max_samples': np.arange(0.01, 1.0, 0.2)}\n",
        "gridSea_cv_baglinR = GridSearchCV(BaggingRegressor(base_estimator=pipe_linR), params_linR, verbose=1, cv=5)\n",
        "gridSea_cv_baglinR.fit(X_train, y_train)\n",
        "labe_bagging1 = 'CLF1 with bagging'\n",
        "scores_linR_2=cross_val_score(estimator=gridSea_cv_baglinR,X=X_train,y=y_train,cv=5,scoring='neg_mean_squared_error')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# score of test data\n",
        "scoreOfTest_bagl = gridSea_cv_baglinR.score(X_test,y_test)\n",
        "\n",
        "print(\"MSE: %0.2f (+/- %0.2f) [%s]\"% (-scores_linR_2.mean(), scores_linR_2.std(), labe_bagging1))\n",
        "print('Best parameters of max_samples : %0.2f'% gridSea_cv_baglinR.best_params_['max_samples'])\n",
        "print('Best parameters of n_estimators : %0.2f'% gridSea_cv_baglinR.best_params_['n_estimators'])\n",
        "print('Score of test data : %0.2f'% scoreOfTest_bagl)"
      ],
      "metadata": {
        "id": "2p2sKucCpER5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0AX2tBn3pzq"
      },
      "source": [
        "2) Decision tree regressor with bagging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vx7SGFQ-3hiV",
        "outputId": "63f241a8-3b70-43cd-a4a4-baa0c855aadb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "MSE: 0.45 (+/- 0.04) [Decision tree regressor with bagging] Best parameters of max_samples : 0.21 Best parameters of n_estimators : 110.00\n"
          ]
        }
      ],
      "source": [
        "params_deciTreeReg = {'n_estimators': np.arange(50, 250, 20), 'max_samples': np.arange(0.01, 1.0, 0.2)}\n",
        "gridSea_cv_bagdeciTreeReg = GridSearchCV(BaggingRegressor(base_estimator=pipe_deciTreeReg), params_deciTreeReg, verbose=1, cv=5)\n",
        "gridSea_cv_bagdeciTreeReg.fit(X_train, y_train)\n",
        "labe_bagging2 = 'Decision tree regressor with bagging'\n",
        "scores_deciTreeReg_2=cross_val_score(estimator=gridSea_cv_bagdeciTreeReg,X=X_train,y=y_train,cv=5,scoring='neg_mean_squared_error')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# score of test data\n",
        "scoreOfTest_bagd = gridSea_cv_baglinR.score(X_test,y_test)\n",
        "\n",
        "print(\"MSE: %0.2f (+/- %0.2f) [%s]\"% (-scores_deciTreeReg_2.mean(), scores_deciTreeReg_2.std(), labe_bagging2))\n",
        "print('Best parameters of max_samples : %0.2f'% gridSea_cv_bagdeciTreeReg.best_params_['max_samples'])\n",
        "print('Best parameters of n_estimators : %0.2f'% gridSea_cv_bagdeciTreeReg.best_params_['n_estimators'])\n",
        "print('Score of test data : %0.2f'% scoreOfTest_bagd)"
      ],
      "metadata": {
        "id": "cZo4GJOfpCP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufLd6h-afCAZ"
      },
      "source": [
        "3) Support vector regression with bagging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOn_N6ewe9CP",
        "outputId": "fb36c761-aaf2-4b04-8f3b-f536fe7b1d4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
            "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
            "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
            "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
            "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
            "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
            "MSE: 0.32 (+/- 0.05) [Support vector regression with bagging] Best parameters of max_samples : 0.51 Best parameters of n_estimators : 50.00\n"
          ]
        }
      ],
      "source": [
        "params_supVecReg = {'n_estimators': np.arange(50, 250, 50), 'max_samples': np.arange(0.01, 1.0, 0.2)}\n",
        "gridSea_cv_bagsupVecReg = GridSearchCV(BaggingRegressor(base_estimator=pipe_supVecReg), params_supVecReg, verbose=1, cv=5)\n",
        "gridSea_cv_bagsupVecReg.fit(X_train, y_train)\n",
        "labe_bagging3 = 'Support vector regression with bagging'\n",
        "scores_supVecReg_2=cross_val_score(estimator=gridSea_cv_bagsupVecReg,X=X_train,y=y_train,cv=5,scoring='neg_mean_squared_error')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# score of test data\n",
        "scoreOfTest_bags = gridSea_cv_baglinR.score(X_test,y_test)\n",
        "\n",
        "print(\"MSE: %0.2f (+/- %0.2f) [%s]\"% (-scores_supVecReg_2.mean(), scores_supVecReg_2.std(), labe_bagging3))\n",
        "print('Best parameters of max_samples : %0.2f'% gridSea_cv_bagsupVecReg.best_params_['max_samples'])\n",
        "print('Best parameters of n_estimators : %0.2f'% gridSea_cv_bagsupVecReg.best_params_['n_estimators'])\n",
        "print('Score of test data : %0.2f'% scoreOfTest_bags)"
      ],
      "metadata": {
        "id": "KUML_Dr_o2bL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xY3bKX9UfkIK"
      },
      "source": [
        "Third\n",
        "\n",
        "Build an Adaboost regression model for each classifier and evaluate its \n",
        "performance using 10-fold cross validation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-i9VK7iuflhM"
      },
      "source": [
        "1) linear regression with Adaboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weEolNIC2Grf",
        "outputId": "f4adf362-1648-499c-d3de-0a367b9730be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "MSE: 0.29 (+/- 0.03) [CLF1 with Adaboost]\n",
            "Best parameters of max_samples : 0.01\n",
            "Best parameters of n_estimators : 70.00\n",
            "Score of test data : 0.73\n"
          ]
        }
      ],
      "source": [
        "params_linR_2 = {'n_estimators': np.arange(50, 250, 20), 'learning_rate': np.arange(0.01, 1.0, 0.2)}\n",
        "gridSea_cv_adalinR = GridSearchCV(AdaBoostRegressor(base_estimator=pipe_linR), params_linR_2, verbose=1, cv=5)\n",
        "gridSea_cv_adalinR.fit(X_train, y_train)\n",
        "labe_ada1 = 'CLF1 with Adaboost'\n",
        "scores_linR_3=cross_val_score(estimator=gridSea_cv_adalinR,X=X_train,y=y_train,cv=5,scoring='neg_mean_squared_error')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFQ606hNZrkj"
      },
      "outputs": [],
      "source": [
        "# score of test data\n",
        "scoreOfTest_adal = gridSea_cv_adalinR.score(X_test,y_test)\n",
        "\n",
        "print(\"MSE: %0.2f (+/- %0.2f) [%s]\"% (-scores_linR_3.mean(), scores_linR_3.std(), labe_ada1))\n",
        "print('Best parameters of learning_rate : %0.2f'% gridSea_cv_adalinR.best_params_['learning_rate'])\n",
        "print('Best parameters of n_estimators : %0.2f'% gridSea_cv_adalinR.best_params_['n_estimators'])\n",
        "print('Score of test data : %0.2f'% scoreOfTest_adal)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rigr7NwZfvwb"
      },
      "source": [
        "2) Decision tree regressor with Adaboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_i9EY1hf2JL",
        "outputId": "048ad3f8-7af7-492a-c062-bdda562dafa7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE: 0.49 (+/- 0.05) [Decision tree regressor with Adaboost]\n"
          ]
        }
      ],
      "source": [
        "params_deciTreeReg_2 = {'n_estimators': np.arange(50, 250, 20), 'learning_rate': np.arange(0.01, 1.0, 0.2)}\n",
        "gridSea_cv_adadeciTreeReg = GridSearchCV(AdaBoostRegressor(base_estimator=pipe_deciTreeReg), params_deciTreeReg_2, verbose=1, cv=5)\n",
        "gridSea_cv_adadeciTreeReg.fit(X_train, y_train)\n",
        "labe_ada2 = 'Decision tree regressor with Adaboost'\n",
        "scores_deciTreeReg_3=cross_val_score(estimator=gridSea_cv_adadeciTreeReg,X=X_train,y=y_train,cv=5,scoring='neg_mean_squared_error')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LlVS2XNwZu9x"
      },
      "outputs": [],
      "source": [
        "# score of test data\n",
        "scoreOfTest_adad = gridSea_cv_adadeciTreeReg.score(X_test,y_test)\n",
        "\n",
        "print(\"MSE: %0.2f (+/- %0.2f) [%s]\"% (-scores_deciTreeReg_3.mean(), scores_deciTreeReg_3.std(), labe_ada2))\n",
        "print('Best parameters of learning_rate : %0.2f'% gridSea_cv_adadeciTreeReg.best_params_['learning_rate'])\n",
        "print('Best parameters of n_estimators : %0.2f'% gridSea_cv_adadeciTreeReg.best_params_['n_estimators'])\n",
        "print('Score of test data : %0.2f'% scoreOfTest_adad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1c2F0JSvmcF"
      },
      "source": [
        "3) Support vector regression with Adaboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ez_rzEv7vlJf",
        "outputId": "d72b6b81-d06d-4b45-ac41-c4cdad7695ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE: 0.44 (+/- 0.13) [Support vector regression with Adaboost]\n"
          ]
        }
      ],
      "source": [
        "params_supVecReg_2 = {'n_estimators': np.arange(50, 250, 30), 'learning_rate': np.arange(0.01, 1.0, 0.1)}\n",
        "gridSea_cv_adasupVecReg = GridSearchCV(AdaBoostRegressor(base_estimator=pipe_supVecReg), params_supVecReg_2, verbose=1, cv=5)\n",
        "gridSea_cv_adasupVecReg.fit(X_train, y_train)\n",
        "labe_ada3 = 'Support vector regression with Adaboost'\n",
        "scores_supVecReg_3=cross_val_score(estimator=gridSea_cv_adasupVecReg,X=X_train,y=y_train,cv=5,scoring='neg_mean_squared_error')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7504UP_HZzXP"
      },
      "outputs": [],
      "source": [
        "# score of test data\n",
        "scoreOfTest_adas = gridSea_cv_adasupVecReg.score(X_test,y_test)\n",
        "\n",
        "print(\"MSE: %0.2f (+/- %0.2f) [%s]\"% (-scores_supVecReg_3.mean(), scores_supVecReg_3.std(), labe_ada3))\n",
        "print('Best parameters of learning_rate : %0.2f'% gridSea_cv_adasupVecReg.best_params_['learning_rate'])\n",
        "print('Best parameters of n_estimators : %0.2f'% gridSea_cv_adasupVecReg.best_params_['n_estimators'])\n",
        "print('Score of test data : %0.2f'% scoreOfTest_adas)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}